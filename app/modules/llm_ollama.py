class OllamaLLM:
    """Placeholder LLM module using an Ollama API."""
    def generate(self, prompt: str) -> str:
        """Return a canned response for now."""
        # TODO: integrate with actual Ollama server
        return f"You said: {prompt}"

